{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchtext tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SET LIBRARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, sys\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from torchtext import data, datasets\n",
    "from torchtext.vocab import GloVe, FastText, CharNGram\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pwd\n",
    "#!tar xvzf nmr-100k.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = pd.read_csv('/jet/prs/workspace/nmr-100k.csv',delimiter='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SANITY CHECK\n",
    "print(len(tab.loc[0,'rviw_modd'].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab['label'] = np.where(tab.rviw_rate>7, \"pos\", np.where(tab.rviw_rate==1, \"neg\", \"neu\"))\n",
    "tab['input'] = tab.rviw_modd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_train</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>30610</td>\n",
       "      <td>51233</td>\n",
       "      <td>194088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>396261</td>\n",
       "      <td>750659</td>\n",
       "      <td>2831706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label        neg     neu      pos\n",
       "is_train                         \n",
       "False      30610   51233   194088\n",
       "True      396261  750659  2831706"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(tab.is_train, tab.label, margins=False)#.apply(lambda r: round(r/r.sum(),3), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/var/python/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/jet/var/python/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "tab[tab.is_train==True][tab.label.isin(['pos','neg'])].loc[:,['label','input']].to_json('train.json',orient='records',lines=True) #.sample(frac=0.1, replace=False)\n",
    "tab[tab.is_train!=True][tab.label.isin(['pos','neg'])].loc[:,['label','input']].to_json('valid.json',orient='records',lines=True) #.sample(frac=0.1, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = data.Field(fix_length=50, batch_first=False)\n",
    "LABEL = data.Field(sequential=False,)\n",
    "\n",
    "fields = {'label': ('label', LABEL), 'input': ('input', INPUT)}\n",
    "\n",
    "train, valid = data.TabularDataset.splits(\n",
    "    path = '/jet/prs/workspace',\n",
    "    train = 'train.json',\n",
    "    test = 'valid.json',\n",
    "    format = 'json',\n",
    "    fields = fields\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'pos', 'input': ['24151', '49437', '14146', '29768', '16450', '12248', '12248', '24151', '49437', '44879', '18715', '51458', '43907', '20743', '24116', '27813', '18196', '48998', '43703', '34396', '6247', '40398', '30707', '24173', '7767', '35830', '43062', '56983', '6322', '48998', '21323', '14146', '52824', '10', '23685', '52516', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT.build_vocab(train, vectors=GloVe(name='6B', dim=300), max_size=10000, min_freq=10)\n",
    "LABEL.build_vocab(train,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR DEBUGGING ONLY\n",
    "\n",
    "#print(INPUT.vocab.freqs)\n",
    "#print(INPUT.vocab.vectors)\n",
    "#print(INPUT.vocab.stoi)\n",
    "\n",
    "INPUT = data.Field(fix_length=50, batch_first=False)\n",
    "LABEL = data.Field(sequential=False,)\n",
    "\n",
    "train, valid = datasets.IMDB.splits(INPUT, LABEL)\n",
    "\n",
    "INPUT.build_vocab(train, vectors=GloVe(name='6B', dim=300), max_size=10000, min_freq=10)\n",
    "LABEL.build_vocab(train,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    }
   ],
   "source": [
    "g_train, g_valid = data.BucketIterator.splits((train, valid), batch_size=32, device=-1, shuffle=True, sort=False)\n",
    "g_train.repeat = False\n",
    "g_valid.repeat = False\n",
    "dataloader = {'train':g_train, 'valid':g_valid}\n",
    "dataset_sizes = {'train':len(g_train.dataset),'valid':len(g_valid.dataset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 32])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# SANITY CHECK\n",
    "batch = next(iter(dataloader['train']))\n",
    "x_input = batch.input.cuda()\n",
    "y_label = batch.label.cuda()\n",
    "print(x_input.size())\n",
    "print(y_label.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gph(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_vocab, n_hidden, n_label, btch_size=1, nl=2):\n",
    "        super().__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.btch_size = btch_size\n",
    "        self.nl = nl\n",
    "        self.embd = nn.Embedding(n_vocab, n_hidden)\n",
    "        self.rnn = nn.LSTM(n_hidden, n_hidden, nl)\n",
    "        self.fcn = nn.Linear(n_hidden, n_label)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "    def forward(self, x_input):\n",
    "        bs = x_input.size()[1]\n",
    "        if btch_size != self.btch_size:\n",
    "            self.btch_size = btch_size\n",
    "        embd = self.embd(x_input)\n",
    "        \n",
    "        h0 = c0 = Variable(embd.data.new(*(self.nl, self.btch_size, self.n_hidden)).zero_())\n",
    "        rnn, _ = self.rnn(embd,(h0, c0))\n",
    "        rnn = rnn[-1]\n",
    "        fcn = F.dropout(self.fcn(rnn), p=0.8)\n",
    "        return self.softmax(fcn)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SET PARMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vocab = len(INPUT.vocab)\n",
    "n_hidden = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gph = Gph(n_vocab, n_hidden, n_label=3, btch_size=32)    \n",
    "if torch.cuda.is_available():\n",
    "    gph = gph.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(gph.parameters(), lr=learning_rate)\n",
    "\n",
    "#gph.embd.weight.requires_grad = False\n",
    "#optimizer = optim.SGD([parm for parm in gph.parameters() if parm.requires_grad==True], lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gph(gph, optimizer, dataloader, phase='train', volatile=False):\n",
    "    if phase == 'train':\n",
    "        gph.train()\n",
    "    if phase == 'valid':\n",
    "        gph.eval()\n",
    "        volatile = True\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    running_counts = 0\n",
    "\n",
    "    for idx, batch in enumerate(dataloader[phase]):\n",
    "        if torch.cuda.is_available():\n",
    "            x_input, y_label = batch.input.cuda(), batch.label.cuda()\n",
    "\n",
    "        if phase == 'train':\n",
    "            optimizer.zero_grad()\n",
    "        y_prob = gph(x_input)\n",
    "        _, y_pred = torch.max(y_prob, 1)\n",
    "        loss = F.nll_loss(y_prob, y_label)\n",
    "\n",
    "        if phase == 'train':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_corrects += torch.sum(y_pred == y_label.data).item()\n",
    "        running_counts += len(y_pred)\n",
    "\n",
    "    epoch_loss = running_loss / running_counts\n",
    "    epoch_acc = running_corrects / running_counts\n",
    "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0043 Acc: 0.9485\n",
      "valid Loss: 0.0046 Acc: 0.9439\n",
      "train Loss: 0.0035 Acc: 0.9576\n",
      "valid Loss: 0.0045 Acc: 0.9456\n",
      "train Loss: 0.0034 Acc: 0.9597\n",
      "valid Loss: 0.0045 Acc: 0.9459\n",
      "train Loss: 0.0033 Acc: 0.9609\n",
      "valid Loss: 0.0045 Acc: 0.9463\n",
      "train Loss: 0.0032 Acc: 0.9617\n",
      "valid Loss: 0.0045 Acc: 0.9461\n",
      "train Loss: 0.0032 Acc: 0.9623\n",
      "valid Loss: 0.0045 Acc: 0.9459\n",
      "train Loss: 0.0031 Acc: 0.9627\n",
      "valid Loss: 0.0045 Acc: 0.9464\n",
      "train Loss: 0.0031 Acc: 0.9630\n",
      "valid Loss: 0.0044 Acc: 0.9463\n",
      "train Loss: 0.0031 Acc: 0.9632\n",
      "valid Loss: 0.0044 Acc: 0.9464\n",
      "train Loss: 0.0031 Acc: 0.9635\n",
      "valid Loss: 0.0045 Acc: 0.9462\n",
      "train Loss: 0.0031 Acc: 0.9636\n",
      "valid Loss: 0.0044 Acc: 0.9467\n",
      "train Loss: 0.0031 Acc: 0.9638\n",
      "valid Loss: 0.0045 Acc: 0.9462\n",
      "train Loss: 0.0031 Acc: 0.9638\n",
      "valid Loss: 0.0045 Acc: 0.9461\n",
      "train Loss: 0.0031 Acc: 0.9638\n",
      "valid Loss: 0.0045 Acc: 0.9465\n",
      "train Loss: 0.0030 Acc: 0.9641\n",
      "valid Loss: 0.0045 Acc: 0.9459\n"
     ]
    }
   ],
   "source": [
    "# DEBUGGED\n",
    "# https://discuss.pytorch.org/t/data-iterator-failing-on-dev-set-only/11956/4\n",
    "train_loss, train_acc = [],[]\n",
    "valid_loss, valid_acc = [],[]\n",
    "for epoch in range(1,16):\n",
    "    epoch_loss, epoch_acc = train_gph(gph, optimizer, dataloader, phase='train')\n",
    "    vld_loss, vld_acc = train_gph(gph, optimizer, dataloader, phase='valid')\n",
    "    train_loss.append(epoch_loss)\n",
    "    train_acc.append(epoch_acc)\n",
    "    valid_loss.append(vld_loss)\n",
    "    valid_acc.append(vld_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
